---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a fourth year PhD candidate in Computer Science at [UMass Amherst](https://www.cics.umass.edu/), advised by [Professor Andrew Lan](https://people.umass.edu/~andrewlan/), with a focus on Machine learning. My PhD research is on improving data selection efficiency with differentiable optimization layers (and avoid *heuristic* informativeness measures).  Recently, I won the [NeurIPS 2020 education challenge](https://eedi.com/projects/neurips-education-challenge) for the task of improving question selection efficiency in personalized tests (e.g., GRE, GMAT). I also work on robust models for learning with limited, weakly supervised, and noisy labels. During my PhD, I was able to squeeze in two research internships at [Adobe Research](https://research.adobe.com/), advised [Dr. Saayan Mitra](https://research.adobe.com/person/saayan-mitra/), [Dr. Somdeb Sarkhel](https://research.adobe.com/person/somdeb-sarkhel/), and [Dr. Vishy Swaminathan](https://research.adobe.com/person/vishy-swaminathan/), where I was fortunate to work on optimal bidding strategy in real-time bidding systems. Before my PhD, I have been a Software Engineer (Applied Scientist) at the [Microsoft BingAds](https://www.microsoft.com/en-in/msidc/bangalore-campus.aspx) division where I had the opportunity to work on improving click performance and ad selection algorithms, working closely with [Rahul Agrawal](https://scholar.google.co.in/citations?user=AGrdeCIAAAAJ&hl=en). Even before that, I had amazing years in the [Indian Institute of Science, Bangalore (IISc)](http://www.ee.iisc.ac.in/), advised by [Professor P.S. Sastry](http://www.ee.iisc.ac.in/faculty/sastry/), where I had started working on robust learning under noisy labels. I have been fortunate to work with some amazing researchers and publish in many exciting machine learning/data mining conferences and workshops such as AAAI, CVPR, ICML, IJCAI, KDD, SIAM SDM. I also received the Best Student Paper Award from the [IEEE Big Data](https://bigdataieee.org/BigData2020/index.html) (2020) conference. 

<!-- **Biased Personal Views**

My broad goal is to learn *anything and everything* and avoid introducing **any** human domain knowledge in the learning framework (apologies to many great minds). In *most cases*, I am influenced by [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html). Stay foolish and let the *Data* speak! Opinions expressed are solely my own and do not express the views or opinions of my employer. -->

**Research Interest**
  * Meta Learning, Differentiable Optimization Layers, Bi-level Optimization
  * Sequential Models, Reinforcement Learning, Inverse Reinforcement Learning
  * Computational Advertising, Computer Vision, NLP, AI for Social Goods

**Updates**
<div class="posts-wrapper">
    <div class="post" style="width:800px;height:200px;border:1px solid;overflow:auto">
        <ul class="news">
            <li><strong>Dec 2021: </strong>paper on Differentiable Sketching in Recommender Systems has been accepted at <a href="https://aaai.org/Conferences/AAAI-22/">AAAI 2022</a> (15% (1349/9020) Acceptance rate!).
            </li>
            <li><strong>Nov 2021: </strong> honored to receive <strong> 2021 Duolingo Dissertation Award</strong>.
            </li>
            <li><strong>Apr 2021: </strong>paper on computerized adaptive testing under bilevel framework has been accepted at <a href="https://ijcai-21.org/">IJCAI 2021</a> (13.9% Acceptance rate!).
            </li>
            <li><strong>Apr 2021: </strong>paper on learning with noisy labels with contrastive initialization to appear at <strong>LLID Workhop</strong> at <a href="https://l2id.github.io/index.html">CVPR 2021</a>.
            </li>
            <li><strong>Dec 2020: </strong>honored to get the <strong>Best Student Paper Award</strong> at <a href="https://bigdataieee.org/BigData2020/">IEEE Big Data 2020</a>.
            </li>
            <li><strong>Nov 2020: </strong>won the personalized question selection task in  <a href="https://competitions.codalab.org/competitions/25449">NeurIPS 2020 Education Challenge</a>. Implementation is publicly <a href="https://github.com/arghosh/NeurIPSEducation2020">available</a>.
            </li>
            <li><strong>Nov 2020: </strong>paper on robust sample reweighting strategy without gold samples to appear at <a href="http://wacv2021.thecvf.com/home">WACV 2021</a>. Paper/codes will be released soon.
            </li>
            <li><strong>Nov 2020: </strong>paper on optimal career trajectory modeling to appear at <a href="https://bigdataieee.org/BigData2020/">IEEE Big Data 2020</a>. Paper/codes will be released soon.
            </li>
            <li><strong>Sep 2020: </strong>I will be serving as Program committee member for <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a> and <a href="http://wacv2021.thecvf.com/home">WACV 2021</a> .
            </li>
            <li><strong>Aug 2020: </strong>selected for <a href="https://www.kdd.org/kdd2020/">KDD 2020</a> Student Award!
            </li>
            <li><strong>May 2020: </strong>paper on knowledge tracing to appear at <a href="https://www.kdd.org/kdd2020/">KDD 2020</a>. Paper/codes/data will be released soon.
            </li>
            <li><strong>Mar 2020: </strong>selected for <a href="https://www.siam.org/conferences/cm/lodging-and-support/travel-support/sdm20-travel-support">SIAM SDM Student Travel Award</a>.
            </li>
            <li><strong>Dec 2019: </strong>paper on <a href="https://arxiv.org/pdf/2004.00100">optimal bidding strategy</a> to appear at SIAM SDM 2020.
            </li>
            <!-- <li><strong>Jun 2019: </strong>paper on <a href="https://arxiv.org/pdf/2001.06587">bid landscape forecasting</a> to appear at ECML-PKDD 2019.
            </li> -->
            <li><strong>May 2019: </strong>paper on <a href="https://pdfs.semanticscholar.org/cdbe/99c87f0e94e363acba70b015360ec7d63521.pdf">point processes</a> to appear at ICML Time series workshop 2019.
            </li>
            <li><strong>May 2019: </strong> I will be joining Adobe Research, San Jose for internship (again).
            </li>
            <li><strong>Sep 2018: </strong> Had a great summer at Adobe Research, San Jose.
            </li>
            <li><strong>Aug 2017: </strong> Last day at Microsoft!
            </li>
            <li><strong>Jul 2017: </strong> I will be joining UMass Amherst for PhD in Computer Science.
            </li>
            <li><strong>Feb 2017: </strong>paper on <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14759/14355">robust loss functions for deep networks</a> to appear at AAAI 2017.
            </li>
            <!-- <li><strong>Jan 2017: </strong>paper on <a href="https://arxiv.org/pdf/1605.06296.pdf">robustness of decision trees</a> to appear at PAKDD 2017.
            </li> -->
        </ul>
    </div>
</div>
<br/>

**Publications**
{% include papers.md %}